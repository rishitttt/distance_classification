## Report

#### 1. What are the common distance metrics used in distance-based classification algorithms?
Euclidean, Manhattan, Minkowski, Hamming, Cosine.

#### 2. What are some real-world applications of distance-based classification algorithms?
Image recognition, medical diagnosis, fraud detection.

#### 3. Explain various distance metrics.
- **Euclidean** - Direct distance in a straight line/vector, as movement is not bounded by angle/direction.
- **Manhattan** - Sum of absolute x and y distance, as only four directions are considered.
- **Minkowski** - Variable formula for distance, this can be used to derive the Euclidean and Manhattan distance.
- **Hamming** - Number of positions where the elements differ.
- **Cosine** - Angle between two vectors.

#### 4. What is the role of cross-validation in model performance?
Cross-validation helps a model improve its performance by running it through multiple validation sets, which helps in the reduction of overfitting and also tunes parameters accordingly.

#### 5. Explain variance and bias in terms of KNN.
- **Bias** is associated with underfitting, which is the result of a large K value. This means that the model does not fit the training data well, resulting in poor performance.
- **Variance**, on the other hand, is associated with overfitting, which is the result of a small K value. This means that the model fits the training set too closely, making it sensitive to noise and potentially performing poorly on new data.

## WandB Screenshots
